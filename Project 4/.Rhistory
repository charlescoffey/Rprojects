#     mse = mean((prct_county$Trump.Share-yhat.lasso)^2)
#
#     if (mse < mse_min){
#
#       mse_min = mse
#       print(c(mse_min, idx)) using this as debugging code
#       choice_lamba = mod_lasso$lambda[idx]
#
#     }
# }
print(paste(toString(choice_lamba), " is the best lambda value with an in-sample MSE value of ", toString(mse_min), "."))
prctest = read.csv("pres_results_by_county_test.csv")
prctest_county = prctest[prctest$Geographic.Subtype == "County",]
prctest_county$Trump.Share = prctest_county$Donald.J..Trump/prctest_county$Total.Vote #this is is trump share with  the NA values still included
prctest_county = prctest_county[!is.na(prctest_county$Trump.Share),]
prctest_subset = prctest_county[, c(9:59)] #what we are putting into regression
yhat.lasso = predict(mod_lasso, newx=as.matrix(prctest_subset), s=choice_lamba)
mse = mean((prctest_county$Trump.Share-yhat.lasso)^2)
print(mse)
plot(prctest_county$Trump.Share, yhat.lasso,
xlab = "Actual Vote Share",
ylab = "Predicted Vote Share")
title("Predicted Vote Share against Actual Vote Share") #apparently this should have a length of 413 according to Piazza?
set.seed(02139)
mod_lasso_cross = cv.glmnet(y = prctrain_county$Trump.Share, x = data.matrix(prctrain_subset), alpha = 1)
MSE = c()
for (lambda in mod_lasso_cross$cvm){
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=lambda)
MSE = append(MSE, mean((prctest_county$Trump.Share-yhat.lasso)^2))
}
plot(mod_lasso_cross)
selected_lambda = mod_lasso_cross$lambda.min
selected_MSE = MSE[which(mod_lasso$lambda==mod_lasso_2$lambda.min)]
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
setwd("~/Documents/MIT courses/YEAR3DOCUMENTS/17.835/PSETs/P4")
library(matrixStats)
library(ggplot2)
library(glmnet)
library(e1071)
house_votes = read.csv("house_votes.csv")
taxbill_vote = data.frame(tapply(house_votes$outcome, house_votes$democrat, FUN=sum))
colnames(taxbill_vote) = "Votes"
rownames(taxbill_vote) = c("Republican", "Democrat")
num_repub = sum(house_votes$republican)
num_democ = sum(house_votes$democrat)
repub_house_votes = house_votes[house_votes$republican == 1, ]
set.seed(02139)
training_data_idxs = sort(sample(c(1:203), 160, replace = FALSE))
training_data = repub_house_votes[training_data_idxs,]
test_data = repub_house_votes[-training_data_idxs,]
predictors = training_data[,c(499:657)]
test_data_p = test_data[,c(499:657)] #same subsetted columns as training data
combined_matrix = cbind(training_data$outcome, predictors)
ols_model = lm(combined_matrix$`training_data$outcome` ~. , data = combined_matrix)
print(paste("The unadjusted R^2 for the data is 0.894."))
#did i use this predict function correctly?
yhat_ols = predict(ols_model, newdata = test_data_p)
Y_vote_ols = c()
Y_vote_ols[which(yhat_ols >= 0.5)] = 1
Y_vote_ols[which(yhat_ols < 0.5)] = 0
size = length(yhat_ols)
# for (idx in 1:size){
#   if (yhat_ols[idx] >= 0.5){
#     Y_vote_ols[idx] = 1
#   }
#   else{
#     Y_vote_ols[idx] = 0
#   }
# }
matches_ols = data.frame(Match=integer(size), TruePositive=integer(size), TrueNegative=integer(size), FalsePositive=integer(size), FalseNegative=integer(size))
for (idx in 1:size){
if (Y_vote_ols[idx] == test_data$outcome[idx]){
matches_ols[idx, "Match"] = 1
if ((test_data$outcome[idx] == 1) && (Y_vote_ols[idx] == 1)){
matches_ols[idx, "TruePositive"] = 1
}
if ((test_data$outcome[idx] == 0) && (Y_vote_ols[idx] == 0)){
matches_ols[idx, "TrueNegative"] = 1
}
}
else{
matches_ols[idx, "Match"] = 0
if ((test_data$outcome[idx] == 0) && (Y_vote_ols[idx] == 1)){
matches_ols[idx, "FalsePositive"] = 1
}
if ((test_data$outcome[idx] == 1) && (Y_vote_ols[idx] == 0)){
matches_ols[idx, "FalseNegative"] = 1
}
}
}
num_correct_pred_ols = sum(matches_ols$Match)
precision = sum(matches_ols$TruePositive)/(sum(matches_ols$TruePositive) + sum(matches_ols$FalsePositive))
recall = sum(matches_ols$TruePositive)/(sum(matches_ols$TruePositive) + sum(matches_ols$FalseNegative))
F1 = 2/((1/precision)+(1/recall))
print(paste("Precision: ", toString(precision)))
print(paste("Recall: ", toString(recall)))
print(paste("F1: ", toString(F1)))
svm_model = svm(predictors, training_data$outcome, kernel ="radial")
yhat_svm = predict(svm_model, test_data_p)
Y_vote_svm = c()
Y_vote_svm[which(yhat_svm >= 0.5)] = 1
Y_vote_svm[which(yhat_svm < 0.5)] = 0
size = length(yhat_svm)
# for (idx in 1:size){
#   if (yhat_svm[idx] >= 0.5){
#     Y_vote_svm[idx] = 1
#   }
#   else{
#     Y_vote_svm[idx] = 0
#   }
# }
matches_svm = data.frame(Match=integer(size), TruePositive=integer(size), TrueNegative=integer(size), FalsePositive=integer(size), FalseNegative=integer(size))
for (idx in 1:size){
if (Y_vote_svm[idx] == test_data$outcome[idx]){
matches_svm[idx, "Match"] = 1
if ((test_data$outcome[idx] == 1) && (Y_vote_svm[idx] == 1)){
matches_svm[idx, "TruePositive"] = 1
}
if ((test_data$outcome[idx] == 0) && (Y_vote_svm[idx] == 0)){
matches_svm[idx, "TrueNegative"] = 1
}
}
else{
matches_svm[idx, "Match"] = 0
if ((test_data$outcome[idx] == 0) && (Y_vote_svm[idx] == 1)){
matches_svm[idx, "FalsePositive"] = 1
}
if ((test_data$outcome[idx] == 1) && (Y_vote_svm[idx] == 0)){
matches_svm[idx, "FalseNegative"] = 1
}
}
}
num_correct_pred_svm = sum(matches_svm$Match)
precision = sum(matches_svm$TruePositive)/(sum(matches_svm$TruePositive) + sum(matches_svm$FalsePositive))
recall = sum(matches_svm$TruePositive)/(sum(matches_svm$TruePositive) + sum(matches_svm$FalseNegative))
F1 = 2/((1/precision)+(1/recall))
print(paste("Precision: ", toString(precision)))
print(paste("Recall: ", toString(recall)))
print(paste("F1: ", toString(F1)))
library(randomForest)
rF_model = randomForest(predictors, training_data$outcome, kernel ="radial")
yhat_rF = predict(rF_model, test_data_p)
Y_vote_rF = c()
Y_vote_rF[which(yhat_rF >= 0.5)] = 1
Y_vote_rF[which(yhat_rF < 0.5)] = 0
size = length(yhat_rF)
matches_rF = data.frame(Match=integer(size), TruePositive=integer(size), TrueNegative=integer(size), FalsePositive=integer(size), FalseNegative=integer(size))
for (idx in 1:size){
if (Y_vote_rF[idx] == test_data$outcome[idx]){
matches_rF[idx, "Match"] = 1
if ((test_data$outcome[idx] == 1) && (Y_vote_rF[idx] == 1)){
matches_rF[idx, "TruePositive"] = 1
}
if ((test_data$outcome[idx] == 0) && (Y_vote_rF[idx] == 0)){
matches_rF[idx, "TrueNegative"] = 1
}
}
else{
matches_rF[idx, "Match"] = 0
if ((test_data$outcome[idx] == 0) && (Y_vote_rF[idx] == 1)){
matches_rF[idx, "FalsePositive"] = 1
}
if ((test_data$outcome[idx] == 1) && (Y_vote_rF[idx] == 0)){
matches_rF[idx, "FalseNegative"] = 1
}
}
}
num_correct_pred_rF = sum(matches_rF$Match)
precision = sum(matches_rF$TruePositive)/(sum(matches_rF$TruePositive) + sum(matches_rF$FalsePositive))
recall = sum(matches_rF$TruePositive)/(sum(matches_rF$TruePositive) + sum(matches_rF$FalseNegative))
F1 = 2/((1/precision)+(1/recall))
print(paste("Precision: ", toString(precision)))
print(paste("Recall: ", toString(recall)))
print(paste("F1: ", toString(F1)))
prctrain = read.csv("pres_results_by_county_train.csv")
prctrain_county = prctrain[prctrain$Geographic.Subtype == "County",]
# trump.share = prct_county$Donald.J..Trump/prct_county$Total.Vote #this is is trump share with  the NA values still included
prctrain_county$Trump.Share = prctrain_county$Donald.J..Trump/prctrain_county$Total.Vote #this is is trump share with  the NA values still included
prctrain_county = prctrain_county[!is.na(prctrain_county$Trump.Share),]
# trump.share = trump.share[!is.na(trump.share)]
prctrain_subset = prctrain_county[, c(9:59)] #what we are putting into regression
summary(prctrain_county$Trump.Share)
mod_lasso = glmnet(y = prctrain_county$Trump.Share, x = data.matrix(prctrain_subset), alpha = 1)
mse_min = Inf
choice_lamba = NaN
for (lambda in mod_lasso$lambda){
yhat.lasso = predict(mod_lasso, newx=as.matrix(prctrain_subset), s=lambda)
mse = mean((prctrain_county$Trump.Share-yhat.lasso)^2)
if (mse < mse_min){
mse_min = mse
choice_lamba = lambda
}
}
# mse_min = Inf
# choice_lamba = NaN
#
# for (idx in 1:length(mod_lasso$lambda)){
#
#     yhat.lasso = predict(mod_lasso, newx=as.matrix(prct_subset), s=mod_lasso$lambda[idx])
#
#     mse = mean((prct_county$Trump.Share-yhat.lasso)^2)
#
#     if (mse < mse_min){
#
#       mse_min = mse
#       print(c(mse_min, idx)) using this as debugging code
#       choice_lamba = mod_lasso$lambda[idx]
#
#     }
# }
print(paste(toString(choice_lamba), " is the best lambda value with an in-sample MSE value of ", toString(mse_min), "."))
prctest = read.csv("pres_results_by_county_test.csv")
prctest_county = prctest[prctest$Geographic.Subtype == "County",]
prctest_county$Trump.Share = prctest_county$Donald.J..Trump/prctest_county$Total.Vote #this is is trump share with  the NA values still included
prctest_county = prctest_county[!is.na(prctest_county$Trump.Share),]
prctest_subset = prctest_county[, c(9:59)] #what we are putting into regression
yhat.lasso = predict(mod_lasso, newx=as.matrix(prctest_subset), s=choice_lamba)
mse = mean((prctest_county$Trump.Share-yhat.lasso)^2)
print(mse)
plot(prctest_county$Trump.Share, yhat.lasso,
xlab = "Actual Vote Share",
ylab = "Predicted Vote Share")
title("Predicted Vote Share against Actual Vote Share") #apparently this should have a length of 413 according to Piazza?
set.seed(02139)
mod_lasso_cross = cv.glmnet(y = prctrain_county$Trump.Share, x = data.matrix(prctrain_subset), alpha = 1)
MSE = c()
for (lambda in mod_lasso_cross$cvm){
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=lambda)
MSE = append(MSE, mean((prctest_county$Trump.Share-yhat.lasso)^2))
}
plot(mod_lasso_cross)
selected_lambda = mod_lasso_cross$lambda.min
selected_MSE = MSE[which(mod_lasso_cross$lambda==mod_lasso_cross$lambda.min)]
print(paste("The selected lambda value is", toString(selected_lambda), "with an MSE of", toString(selected_MSE), "."))
set.seed(02139)
mod_lasso_cross = cv.glmnet(y = prctrain_county$Trump.Share, x = data.matrix(prctrain_subset), alpha = 1)
# MSE = c()
# for (lambda in mod_lasso_cross$cvm){
#
#   yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=lambda)
#
#   MSE = append(MSE, mean((prctest_county$Trump.Share-yhat.lasso)^2))
#
# }
plot(mod_lasso_cross)
selected_lambda = mod_lasso_cross$lambda.min
selected_MSE = mod_lasso_cross$cvm[which(mod_lasso_cross$lambda==mod_lasso_cross$lambda.min)]
print(paste("The selected lambda value is", toString(selected_lambda), "with an MSE of", toString(selected_MSE), "."))
yhat.lasso.cross = predit(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(mse.cross)
mse
mse.cross
coeff = mod_lasso_cross$nzero
print(coeff)
View(coeff)
length(coeff)
?predict()
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls(all.names = TRUE))
setwd("~/Documents/MIT courses/YEAR3DOCUMENTS/17.835/PSETs/P4")
library(matrixStats)
library(ggplot2)
library(glmnet)
library(e1071)
house_votes = read.csv("house_votes.csv")
taxbill_vote = data.frame(tapply(house_votes$outcome, house_votes$democrat, FUN=sum))
colnames(taxbill_vote) = "Votes"
rownames(taxbill_vote) = c("Republican", "Democrat")
num_repub = sum(house_votes$republican)
num_democ = sum(house_votes$democrat)
repub_house_votes = house_votes[house_votes$republican == 1, ]
set.seed(02139)
training_data_idxs = sort(sample(c(1:203), 160, replace = FALSE)) #finding random sample indices for data set
training_data = repub_house_votes[training_data_idxs,]
test_data = repub_house_votes[-training_data_idxs,]
predictors = training_data[,c(499:657)]
test_data_p = test_data[,c(499:657)] #same subsetted columns as training data predictors
combined_matrix = cbind(training_data$outcome, predictors)
ols_model = lm(combined_matrix$`training_data$outcome` ~. , data = combined_matrix)
print(paste("The unadjusted R^2 for the data is 0.894."))
yhat_ols = predict(ols_model, newdata = test_data_p)
Y_vote_ols = c()
Y_vote_ols[which(yhat_ols >= 0.5)] = 1
Y_vote_ols[which(yhat_ols < 0.5)] = 0
size = length(yhat_ols)
matches_ols = data.frame(Match=integer(size), TruePositive=integer(size), TrueNegative=integer(size), FalsePositive=integer(size), FalseNegative=integer(size))
for (idx in 1:size){
if (Y_vote_ols[idx] == test_data$outcome[idx]){
matches_ols[idx, "Match"] = 1
if ((test_data$outcome[idx] == 1) && (Y_vote_ols[idx] == 1)){
matches_ols[idx, "TruePositive"] = 1
}
if ((test_data$outcome[idx] == 0) && (Y_vote_ols[idx] == 0)){
matches_ols[idx, "TrueNegative"] = 1
}
}
else{
matches_ols[idx, "Match"] = 0
if ((test_data$outcome[idx] == 0) && (Y_vote_ols[idx] == 1)){
matches_ols[idx, "FalsePositive"] = 1
}
if ((test_data$outcome[idx] == 1) && (Y_vote_ols[idx] == 0)){
matches_ols[idx, "FalseNegative"] = 1
}
}
}
num_correct_pred_ols = sum(matches_ols$Match)
precision = sum(matches_ols$TruePositive)/(sum(matches_ols$TruePositive) + sum(matches_ols$FalsePositive))
recall = sum(matches_ols$TruePositive)/(sum(matches_ols$TruePositive) + sum(matches_ols$FalseNegative))
F1 = 2/((1/precision)+(1/recall))
print(paste("Precision: ", toString(precision)))
print(paste("Recall: ", toString(recall)))
print(paste("F1: ", toString(F1)))
svm_model = svm(predictors, training_data$outcome, kernel ="radial")
yhat_svm = predict(svm_model, test_data_p)
Y_vote_svm = c()
Y_vote_svm[which(yhat_svm >= 0.5)] = 1
Y_vote_svm[which(yhat_svm < 0.5)] = 0
size = length(yhat_svm)
# for (idx in 1:size){
#   if (yhat_svm[idx] >= 0.5){
#     Y_vote_svm[idx] = 1
#   }
#   else{
#     Y_vote_svm[idx] = 0
#   }
# }
matches_svm = data.frame(Match=integer(size), TruePositive=integer(size), TrueNegative=integer(size), FalsePositive=integer(size), FalseNegative=integer(size))
for (idx in 1:size){
if (Y_vote_svm[idx] == test_data$outcome[idx]){
matches_svm[idx, "Match"] = 1
if ((test_data$outcome[idx] == 1) && (Y_vote_svm[idx] == 1)){
matches_svm[idx, "TruePositive"] = 1
}
if ((test_data$outcome[idx] == 0) && (Y_vote_svm[idx] == 0)){
matches_svm[idx, "TrueNegative"] = 1
}
}
else{
matches_svm[idx, "Match"] = 0
if ((test_data$outcome[idx] == 0) && (Y_vote_svm[idx] == 1)){
matches_svm[idx, "FalsePositive"] = 1
}
if ((test_data$outcome[idx] == 1) && (Y_vote_svm[idx] == 0)){
matches_svm[idx, "FalseNegative"] = 1
}
}
}
num_correct_pred_svm = sum(matches_svm$Match)
precision = sum(matches_svm$TruePositive)/(sum(matches_svm$TruePositive) + sum(matches_svm$FalsePositive))
recall = sum(matches_svm$TruePositive)/(sum(matches_svm$TruePositive) + sum(matches_svm$FalseNegative))
F1 = 2/((1/precision)+(1/recall))
print(paste("Precision: ", toString(precision)))
print(paste("Recall: ", toString(recall)))
print(paste("F1: ", toString(F1)))
library(randomForest)
rF_model = randomForest(predictors, training_data$outcome, kernel ="radial")
yhat_rF = predict(rF_model, test_data_p)
Y_vote_rF = c()
Y_vote_rF[which(yhat_rF >= 0.5)] = 1
Y_vote_rF[which(yhat_rF < 0.5)] = 0
size = length(yhat_rF)
matches_rF = data.frame(Match=integer(size), TruePositive=integer(size), TrueNegative=integer(size), FalsePositive=integer(size), FalseNegative=integer(size))
for (idx in 1:size){
if (Y_vote_rF[idx] == test_data$outcome[idx]){
matches_rF[idx, "Match"] = 1
if ((test_data$outcome[idx] == 1) && (Y_vote_rF[idx] == 1)){
matches_rF[idx, "TruePositive"] = 1
}
if ((test_data$outcome[idx] == 0) && (Y_vote_rF[idx] == 0)){
matches_rF[idx, "TrueNegative"] = 1
}
}
else{
matches_rF[idx, "Match"] = 0
if ((test_data$outcome[idx] == 0) && (Y_vote_rF[idx] == 1)){
matches_rF[idx, "FalsePositive"] = 1
}
if ((test_data$outcome[idx] == 1) && (Y_vote_rF[idx] == 0)){
matches_rF[idx, "FalseNegative"] = 1
}
}
}
num_correct_pred_rF = sum(matches_rF$Match)
precision = sum(matches_rF$TruePositive)/(sum(matches_rF$TruePositive) + sum(matches_rF$FalsePositive))
recall = sum(matches_rF$TruePositive)/(sum(matches_rF$TruePositive) + sum(matches_rF$FalseNegative))
F1 = 2/((1/precision)+(1/recall))
print(paste("Precision: ", toString(precision)))
print(paste("Recall: ", toString(recall)))
print(paste("F1: ", toString(F1)))
prctrain = read.csv("pres_results_by_county_train.csv")
prctrain_county = prctrain[prctrain$Geographic.Subtype == "County",]
# trump.share = prct_county$Donald.J..Trump/prct_county$Total.Vote #this is is trump share with  the NA values still included
prctrain_county$Trump.Share = prctrain_county$Donald.J..Trump/prctrain_county$Total.Vote #this is is trump share with  the NA values still included
prctrain_county = prctrain_county[!is.na(prctrain_county$Trump.Share),]
# trump.share = trump.share[!is.na(trump.share)]
prctrain_subset = prctrain_county[, c(9:59)] #what we are putting into regression
summary(prctrain_county$Trump.Share)
mod_lasso = glmnet(y = prctrain_county$Trump.Share, x = data.matrix(prctrain_subset), alpha = 1)
mse_min = Inf
choice_lamba = NaN
for (lambda in mod_lasso$lambda){
yhat.lasso = predict(mod_lasso, newx=as.matrix(prctrain_subset), s=lambda)
mse = mean((prctrain_county$Trump.Share-yhat.lasso)^2)
if (mse < mse_min){
mse_min = mse
choice_lamba = lambda
}
}
print(paste(toString(choice_lamba), " is the best lambda value with an in-sample MSE value of ", toString(mse_min), "."))
prctest = read.csv("pres_results_by_county_test.csv")
prctest_county = prctest[prctest$Geographic.Subtype == "County",]
prctest_county$Trump.Share = prctest_county$Donald.J..Trump/prctest_county$Total.Vote #this is is trump share with  the NA values still included
prctest_county = prctest_county[!is.na(prctest_county$Trump.Share),]
prctest_subset = prctest_county[, c(9:59)] #what we are putting into regression
yhat.lasso = predict(mod_lasso, newx=as.matrix(prctest_subset), s=choice_lamba)
mse = mean((prctest_county$Trump.Share-yhat.lasso)^2)
print(mse)
plot(prctest_county$Trump.Share, yhat.lasso,
xlab = "Actual Vote Share",
ylab = "Predicted Vote Share")
title("Predicted Vote Share against Actual Vote Share") #apparently this should have a length of 413 according to Piazza?
set.seed(02139)
mod_lasso_cross = cv.glmnet(y = prctrain_county$Trump.Share, x = data.matrix(prctrain_subset), alpha = 1)
# MSE = c()
# for (lambda in mod_lasso_cross$cvm){
#
#   yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=lambda)
#
#   MSE = append(MSE, mean((prctest_county$Trump.Share-yhat.lasso)^2))
#
# }
plot(mod_lasso_cross)
selected_lambda = mod_lasso_cross$lambda.min
selected_MSE = mod_lasso_cross$cvm[which(mod_lasso_cross$lambda==mod_lasso_cross$lambda.min)]
print(paste("The selected lambda value is", toString(selected_lambda), "with an MSE of", toString(selected_MSE), "."))
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(mse.cross)
coeff = mod_lasso_cross$nzero
View(prctrain_county$Trump.Share)
length(prctrain_county$Trump.Share)
sum(matches_ols$FalsePositive)
sum(matches_svm$FalsePositive)
print(paste("The MSE for the data is", toString(mse), "."))
prctest = read.csv("pres_results_by_county_test.csv")
prctest_county = prctest[prctest$Geographic.Subtype == "County",]
prctest_county$Trump.Share = prctest_county$Donald.J..Trump/prctest_county$Total.Vote #this is is trump share with  the NA values still included
prctest_county = prctest_county[!is.na(prctest_county$Trump.Share),]
prctest_subset = prctest_county[, c(9:59)] #what we are putting into regression
yhat.lasso = predict(mod_lasso, newx=as.matrix(prctest_subset), s=choice_lamba)
mse = mean((prctest_county$Trump.Share-yhat.lasso)^2)
print(paste("The MSE for the data is", toString(mse), "."))
plot(prctest_county$Trump.Share, yhat.lasso,
xlab = "Actual Vote Share",
ylab = "Predicted Vote Share")
title("Predicted Vote Share against Actual Vote Share") #apparently this should have a length of 413 according to Piazza?
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(paste("The MSE for the data is", toString(mse.cross), "."))
#cross validated model used on test data
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(paste("The MSE for the data is", toString(mse.cross), "."))
print(mse > mse.cross)
#cross validated model used on test data
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(paste("The MSE for the data is", toString(mse.cross), "."))
print("The MSE from the previous model (", toString(mse),") is greateer than the MSE from the cross-validated model(", toString(mse.cross), ") therefore, the cross-validated model performed better.", sep="")
#cross validated model used on test data
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(paste("The MSE for the data is", toString(mse.cross), "."))
print(paste("The MSE from the previous model (", toString(mse),") is greateer than the MSE from the cross-validated model(", toString(mse.cross), ") therefore, the cross-validated model performed better."), sep="")
#cross validated model used on test data
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(paste("The MSE for the data is", toString(mse.cross), "."))
print(paste("The MSE from the previous model (", toString(mse),") is greater than the MSE from the cross-validated model(", toString(mse.cross), "), therefore the cross-validated model performed better."), sep="")
coeff = mod_lasso_cross$nzero
summary(coeff)
coeff = mod_lasso_cross$nzero
head(coeff)
View(mod_lasso_cross)
coeff = mod_lasso_cross$nzero[which(mod_lasso_cross$lambda==selected_lambda)]
View(coeff)
class(mod_lasso_cross$nzero[which(mod_lasso_cross$lambda==selected_lambda)])
coeff = mod_lasso_cross$nzero[which(mod_lasso_cross$lambda==selected_lambda)][1]
print(coeff)
coeff = mod_lasso_cross$nzero[which(mod_lasso_cross$lambda==selected_lambda)][2]
print(coeff)
coeff = mod_lasso_cross$nzero[which(mod_lasso_cross$lambda==selected_lambda)][1]
print(coeff)
which(mod_lasso_cross$lambda==selected_lambda)
#cross validated model used on test data
yhat.lasso.cross = predict(mod_lasso_cross, newx=as.matrix(prctest_subset), s=selected_lambda)
mse.cross = mean((prctest_county$Trump.Share-yhat.lasso.cross)^2)
print(paste("The MSE for the data is", toString(mse.cross), "."))
print(paste("The MSE from the previous model (", toString(mse),") is greater than the MSE from the cross-validated model(", toString(mse.cross), "), therefore the cross-validated model performed better."), sep="")
knitr::purl(“CharlesCoffey17835PSET4.Rmd")
setwd("~/Documents/MIT courses/YEAR3DOCUMENTS/17.835/PSETs/P4")
knitr::purl(“CharlesCoffey17835PSET4.Rmd")
knitr::purl(“CharlesCoffey17835PSET4.Rmd")
knitr::purl(CharlesCoffey17835PSET4.Rmd)
knitr::purl("CharlesCoffey17835PSET4.Rmd")
source('~/Documents/MIT courses/YEAR3DOCUMENTS/17.835/PSETs/P4/CharlesCoffey17835PSET4.R', echo=TRUE)
quit
quit()
